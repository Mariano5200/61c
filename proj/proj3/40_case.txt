    if (n == 40) { //optimized case.
        // # pragma omp parallel
        {
            #pragma omp for
            for(int j = 0; j < n; j++ ) {
                int jn = j*n;
                for(int i = 0; i < 40; i+=20 ) {
                    float *p = C+i+jn;
                    __m128 c1 = _mm_loadu_ps(p);
                    __m128 c2 = _mm_loadu_ps(p+4);
                    __m128 c3 = _mm_loadu_ps(p+8);
                    __m128 c4 = _mm_loadu_ps(p+12);
                    __m128 c5 = _mm_loadu_ps(p+16);

                    #pragma omp critical
                    {
                    int k, kn;
                    float *t, *r;
                    for(k = 0; k < upb2; k+=4) {
                        kn=k*n;
                        t = A+(i+kn);
                        r = A+(jn+j+kn);

                        __m128 a21 = _mm_load1_ps(r);
                        __m128 a22 = _mm_load1_ps(r+n);
                        __m128 a23 = _mm_load1_ps(r+(2*n));
                        __m128 a24 =  _mm_load1_ps(r+(3*n));

                        c1 = _mm_add_ps(c1, _mm_add_ps(_mm_mul_ps(a24, _mm_loadu_ps(t+(3*n))),
                                       _mm_add_ps(_mm_mul_ps(a23, _mm_loadu_ps(t+(2*n))),
                                              _mm_add_ps(_mm_mul_ps(a21, _mm_loadu_ps(t)), _mm_mul_ps(a22, _mm_loadu_ps(t+n))))));
                        c2 = _mm_add_ps(c2, _mm_add_ps(_mm_mul_ps(a24, _mm_loadu_ps(t+4+(3*n))),
                                       _mm_add_ps(_mm_mul_ps(a23, _mm_loadu_ps(t+4+(2*n))),
                                              _mm_add_ps(_mm_mul_ps(a21, _mm_loadu_ps(t+4)), _mm_mul_ps(a22, _mm_loadu_ps(t+4+n))))));
                        c3 = _mm_add_ps(c3, _mm_add_ps(_mm_mul_ps(a24, _mm_loadu_ps(t+8+(3*n))),
                                       _mm_add_ps(_mm_mul_ps(a23, _mm_loadu_ps(t+8+(2*n))),
                                              _mm_add_ps(_mm_mul_ps(a21, _mm_loadu_ps(t+8)), _mm_mul_ps(a22, _mm_loadu_ps(t+8+n))))));
                        c4 = _mm_add_ps(c4, _mm_add_ps(_mm_mul_ps(a24, _mm_loadu_ps(t+12+(3*n))),
                                       _mm_add_ps(_mm_mul_ps(a23, _mm_loadu_ps(t+12+(2*n))),
                                              _mm_add_ps(_mm_mul_ps(a21, _mm_loadu_ps(t+12)), _mm_mul_ps(a22, _mm_loadu_ps(t+12+n))))));
                        c5 = _mm_add_ps(c5, _mm_add_ps(_mm_mul_ps(a24, _mm_loadu_ps(t+16+(3*n))),
                                       _mm_add_ps(_mm_mul_ps(a23, _mm_loadu_ps(t+16+(2*n))),
                                              _mm_add_ps(_mm_mul_ps(a21, _mm_loadu_ps(t+16)), _mm_mul_ps(a22, _mm_loadu_ps(t+16+n))))));
                    } //end main k.
                    for(;k < m; k++) {
                        kn=k*n;
                        t = A+(i+kn);
                        r = A+(jn+j+kn);
                        __m128 a21 = _mm_load1_ps(r);
                        c1 = _mm_add_ps(c1, _mm_mul_ps(_mm_loadu_ps(t), a21));
                        c2 = _mm_add_ps(c2, _mm_mul_ps(_mm_loadu_ps(t+4), a21));
                        c3 = _mm_add_ps(c3, _mm_mul_ps(_mm_loadu_ps(t+8), a21));
                        c4 = _mm_add_ps(c4, _mm_mul_ps(_mm_loadu_ps(t+12), a21));
                        c5 = _mm_add_ps(c5, _mm_mul_ps(_mm_loadu_ps(t+16), a21));
                    } // end k fringe
                    }
                    _mm_storeu_ps(p, c1);
                    _mm_storeu_ps(p+4, c2);
                    _mm_storeu_ps(p+8, c3);
                    _mm_storeu_ps(p+12, c4);
                    _mm_storeu_ps(p+16, c5);
                }
            }
        }

    } else {